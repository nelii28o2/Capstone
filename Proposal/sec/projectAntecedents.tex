\autsection{Project Antecedents}{Nelián Colón}

\subsection{Previous Work Experience}

The members of Team Aguacate have spent 4 years working together in different
projects. Since 2010, they have participated together in programming
competitions, such as IEEE Xtreme, Inter-Universitary Competitions at UPR
Bayamón and UPR Ponce, and Java Battles at UPR Mayagüez, arriving at the top 3
places in all of them. They have also participated in hackathons, such as the
Google 24 Hours Of Good (Nelián) and UPRM's First Hackathon \cite{hack1} (Daniel and Samuel),
which received a special prize for  best MongoDB implementation \cite{hack2}.
In addition, they have done some projects together, such as the Microprocessor
Interfacing course project on the spring semester of 2013, which they called
``WaveSphere" \cite{Micro2}. These previous experiences have allowed the team to
build their technical skills and teamwork abilities.

The team's participation in programming competitions have exposed them to
several  online judges for programming competitions, such as Universidad de
Valladolid's (UVa) judge, \cite{UVA} and the Sphere Online Judge (SPOJ)
\cite{SPOJ}. Team Aguacate has also had the experience of submitting code
assignments for programming labs. These previous experiences have lead the team
to come up with the idea of creating something similar to an online judge to
facilitate not only their own work by making a tool to turn in programming
assignments easier and getting grades faster, but also the instructors' work
since they have to grade hundreds of these assignments.

\subsection{Similar Projects}

Educational Institutions outside of Puerto Rico have similar systems to the one
being proposed. In 1994, the University of Maryland presented Kassandra: The
Automatic Grading System \cite{Matt1994}. As the title suggests, Kassandra is an
automatic grading system that is used for grading assignments in scientific
computing. This system is used by students to check the correctness of their
program assignments. This is achieved by comparing the program output with an
expected result, much like current online judges do. In 2000, the Virginia
Polytechnic Institute and the Microsoft Research Corporation developed Curator,
a web-based electronic submission system that supports automated grading of
elementary programming assignments \cite{Curator}. Its grading mechanism is
similar to Kassandra; the programs are compiled and their output is tested
against a known correct output from a specific input. A few years ago, at the
University of Puerto Rico at Mayagüez (UPRM), a former student and TA for the
Data  Structures course, José Santuche \cite{Santuche}, developed a simple
script that would check-out his students' code, run some tests, compare the
output and send an email to the student with the results. However, it was
unreliable and had to be changed manually between assignments. Currently, the
most competitive product is another web-based tool named Web-CAT. Web-CAT is an
open source automated grading system that is used to grade students on how well
they test their own code. This is different than just comparing output results.
Web-CAT needs to be installed on an institution's own infrastructure
\cite{WebCat}. A similar product to Web-CAT is Praktomat \cite{Praktomat}, an
open source web-based tool for automatic grading.

\subsection{Proposed Approach}

From the aforementioned projects, Panda Code Reviews (Panda) performs
correctness checking on submitted code. Panda differs from the previous efforts
because it is fully Web-based and hosted in the cloud out of the box, so there
is no installation needed and the update process is completely transparent to
institutions and users. Competing products like Web-CAT, Praktomat, Curator, and
Kassandra require additional infrastructure and a set up process. They all have
the hassle of having to manually back up the database and distressingly updating
the infrastructure's software. Moreover, Panda will provide a key missing
feature in all other similar products, code quality analysis, to some extent.

\subsection{Project Importance}

As stated by previous and current TAs, such as José Santuche, it is important to
have an automatic grading tool because the graders gradually become exhausted of
having to grade the same assignment over and over again. As Jesús E. Luzón
mentioned (quoted above), with only 23 students, grading a single assignment
might take him up to 3 hours of his time. As Santuche mentions: \begin{quote}
``Since the process of grading is so exhausting, the graders normally begin by
verifying all the details, but at some point they just verify the output without
looking at the code." \end{quote} From the students' perspective, the process
of submitting code and waiting for a grade is slow and tedious as well. Panda
aims to tackle these problems by providing a centralized and fully integrated
web-based system in which students will be able to submit their assignments and
it will automatically grade them based on code quality and test cases submitted
by the TA or professor. The grade will not be posted immediately, but will allow
the grader to verify it first. This tool helps the grader as much as possible by
giving him or her a preliminary grade, but does not remove control since the
grader makes the final decision about the posted grade. This project will
incorporate the use of Git as a form of code submission, so it also helps
students learn how to use version control and source code management
technologies. All of the features that the tool will provide makes it a great
marketable product, since it will provide more features than the previous 
competing attemps while still being free to use. 

\subsection{Standards and Regulations} Since the tool will manage student data,
it needs to be secure and private. It also needs to maintain the test cases
uploaded by the instructor private to the students. To maintain the information
secure and not visible by anybody, an HTTPS connection will always be required
between Panda and the client's computers. All information will be encrypted in
the system, including credential information, account data, and repository data.
Also, a very sophisticated, third party cloud serving infrastructure will be
used to guarantee data backup and up to 99.99\% uptime: ensuring that the system
will be available always when needed. Virus and malware protection measurments
will be taken: the system will never try to run submitted binary files, the code
will be compiled and executed in a sandbox, the program will be given a time and
memory limit with restricted permissions, and the submissions will be handled by
a global submit queue that will prevent overloading the server while preventing
single users to submit too many jobs at once. More standards can be found in 
Appendix~\ref{sec:stand}.
